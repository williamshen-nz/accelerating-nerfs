{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf03514d",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2577da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent dir to path so we can import accelerating_nerfs\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899904e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0xf but this version of numpy is 0xe (Triggered internally at /root/pytorch/torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import traceback\n",
    "\n",
    "from collections import defaultdict\n",
    "from accelerating_nerfs.models import VanillaNeRF, patch_forward\n",
    "\n",
    "# Custom code\n",
    "from analysis import *\n",
    "from profiler import Profiler\n",
    "from notebook_utils import natural_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49e096",
   "metadata": {},
   "source": [
    "## Load NeRF model\n",
    "We use vanilla NeRFs which are MLPs. Uncomment the cell below to view the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8830c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to view architecture diagram\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(\"./figures/netdiag-modified.pdf\", width=600, height=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85925ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNeRF(\n",
      "  (posi_encoder): SinusoidalEncoder()\n",
      "  (view_encoder): SinusoidalEncoder()\n",
      "  (mlp): NerfMLP(\n",
      "    (base): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sigma_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (bottleneck_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (rgb_layer): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/models.py:254: UserWarning: patched forward of VanillaNeRF to also pass the condition. You should only use this for debugging or with Timeloop and Accelergy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VanillaNeRF()\n",
    "\n",
    "# We need to patch the forward method for the purpose of mapping to pass in ray directions\n",
    "# This ensures the bottleneck layer is captured by the converter from pytorch2timeloop \n",
    "patch_forward(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49336b",
   "metadata": {},
   "source": [
    "## Convert to Timeloop and load sparsity into the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb327e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf\n",
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf-sparse\n"
     ]
    }
   ],
   "source": [
    "# TODO: play around with the batch size\n",
    "batch_size = 128\n",
    "\n",
    "# The unknown module type warnings are ok\n",
    "# We create a copy for nerf-sparse so we can copy the layer sparsities over to the configurations\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf\")\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf-sparse\")\n",
    "nerf_layer_shapes = load_nerf_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c895e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair_sparsity.json  hotdog_sparsity.json     mic_sparsity.json\r\n",
      "drums_sparsity.json  lego_sparsity.json       ship_sparsity.json\r\n",
      "ficus_sparsity.json  materials_sparsity.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../accelerating_nerfs/sparsity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60843261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sparsity results for dict_keys(['chair', 'drums', 'ficus', 'hotdog', 'lego', 'materials', 'mic', 'ship'])\n",
      "Layer to Average Sparsity: {\n",
      "    \"1\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 4.3946616992536214e-08,\n",
      "            \"std\": 4.918707813129488e-07,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.5542258571408987,\n",
      "            \"std\": 0.03391004992789977,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.5542258571408987,\n",
      "            \"std\": 0.03391004992789977,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6947238747829664,\n",
      "            \"std\": 0.03819135012459017,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6947238747829664,\n",
      "            \"std\": 0.03819135012459017,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.7004855604878076,\n",
      "            \"std\": 0.0401906050789546,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.7004855604878076,\n",
      "            \"std\": 0.0401906050789546,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6893779538928241,\n",
      "            \"std\": 0.0344373699693345,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6893779538928241,\n",
      "            \"std\": 0.0344373699693345,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6751321669257815,\n",
      "            \"std\": 0.04897064882230532,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.541798863641495,\n",
      "            \"std\": 0.03929933042345445,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6500948969546201,\n",
      "            \"std\": 0.04782291053415555,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6500948969546201,\n",
      "            \"std\": 0.04782291053415555,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6938947154922879,\n",
      "            \"std\": 0.060957404355100955,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6938947154922879,\n",
      "            \"std\": 0.060957404355100955,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6987572914015378,\n",
      "            \"std\": 0.037907699771396394,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6987572914015378,\n",
      "            \"std\": 0.037907699771396394,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6522592065368036,\n",
      "            \"std\": 0.3742870882921954,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6870557599287539,\n",
      "            \"std\": 0.03621108286053783,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 2.163834528961967e-09,\n",
      "            \"std\": 4.16579726744824e-08,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    },\n",
      "    \"11\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 2.4972324112363578e-09,\n",
      "            \"std\": 6.142307098905525e-08,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.7121127001079874,\n",
      "            \"std\": 0.06476021563616605,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    },\n",
      "    \"12\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.7121127001079874,\n",
      "            \"std\": 0.06476021563616605,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.0,\n",
      "            \"std\": 0.0,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load layer sparsity results\n",
    "sparsities = load_nerf_sparsities(\"../accelerating_nerfs/sparsity\")\n",
    "layer_to_avg_sparsity = compute_layer_sparsities(sparsities)\n",
    "print(\"Layer to Average Sparsity:\", json.dumps(layer_to_avg_sparsity, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af8bfc",
   "metadata": {},
   "source": [
    "### Load the sparsity results into the Timeloop layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3874398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added densities: {'Inputs': 0.999999956053383, 'Weights': 1.0, 'Outputs': 0.44577414285910133}\n",
      "Layer 2 added densities: {'Inputs': 0.44577414285910133, 'Weights': 1.0, 'Outputs': 0.3052761252170336}\n",
      "Layer 3 added densities: {'Inputs': 0.3052761252170336, 'Weights': 1.0, 'Outputs': 0.29951443951219237}\n",
      "Layer 4 added densities: {'Inputs': 0.29951443951219237, 'Weights': 1.0, 'Outputs': 0.3106220461071759}\n",
      "Layer 5 added densities: {'Inputs': 0.3106220461071759, 'Weights': 1.0, 'Outputs': 0.3248678330742185}\n",
      "Layer 6 added densities: {'Inputs': 0.458201136358505, 'Weights': 1.0, 'Outputs': 0.3499051030453799}\n",
      "Layer 7 added densities: {'Inputs': 0.3499051030453799, 'Weights': 1.0, 'Outputs': 0.3061052845077121}\n",
      "Layer 8 added densities: {'Inputs': 0.3061052845077121, 'Weights': 1.0, 'Outputs': 0.30124270859846225}\n",
      "Layer 9 added densities: {'Inputs': 0.30124270859846225, 'Weights': 1.0, 'Outputs': 0.3477407934631964}\n",
      "Layer 10 added densities: {'Inputs': 0.3129442400712461, 'Weights': 1.0, 'Outputs': 0.9999999978361654}\n",
      "Layer 11 added densities: {'Inputs': 0.9999999975027676, 'Weights': 1.0, 'Outputs': 0.28788729989201256}\n",
      "Layer 12 added densities: {'Inputs': 0.28788729989201256, 'Weights': 1.0, 'Outputs': 1.0}\n"
     ]
    }
   ],
   "source": [
    "add_sparsity_to_nerf_layers(layer_to_avg_sparsity, layer_dir=\"workloads/nerf-sparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870967",
   "metadata": {},
   "source": [
    "### Configure saving of profiling results\n",
    "This isn't important so you can ignore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41223636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results in this dictionary\n",
    "profile_results = {}\n",
    "\n",
    "# Setup saving the profiling results\n",
    "results_dir = \"profile_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    all_other_results = {}\n",
    "    \n",
    "    for arch, arch_results in profile_results.items():\n",
    "        # Write the super long results to it's own file\n",
    "        arch_results_path = os.path.join(results_dir, f\"{arch}_results.json\")\n",
    "        with open(arch_results_path, \"w\") as f:\n",
    "            json.dump(arch_results[\"results\"], f, indent=4)\n",
    "        \n",
    "        # Accumulate the other results as they're shorter and more readable\n",
    "        other_results = {\n",
    "            k: v for k, v in arch_results.items()\n",
    "            if k != \"results\"\n",
    "        }\n",
    "        # Have a pointer to the separate results file\n",
    "        other_results[\"results\"] = os.path.abspath(arch_results_path)\n",
    "        all_other_results[arch] = other_results\n",
    "    \n",
    "    results_path = os.path.join(results_dir, \"results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(all_other_results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved profile results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf13f07",
   "metadata": {},
   "source": [
    "## Profile using Timeloop and Accelergy\n",
    "I think we can safely ignore the 'No handlers found'\n",
    "\n",
    "To rerun things, delete the existing results in the `profiled_libs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4fa1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Running eyeriss_like\n",
      "====================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_area: 0.0\n",
      "total_energy: 1211.45\n",
      "total_cycle: 1136384.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "================================\n",
      "Running simple_weight_stationary\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 6/6 [07:57<00:00, 79.64s/it] \n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_269/3037256322.py\", line 25, in <module>\n",
      "    results, summary, layer_summary = profiler.profile()\n",
      "  File \"/home/workspace/notebooks/profiler.py\", line 348, in profile\n",
      "    self.populate_profiled_lib(layer_info)\n",
      "  File \"/home/workspace/notebooks/profiler.py\", line 297, in populate_profiled_lib\n",
      "    info = {key: layer_info[layer_id][key] for key in keys_to_include}\n",
      "  File \"/home/workspace/notebooks/profiler.py\", line 297, in <dictcomp>\n",
      "    info = {key: layer_info[layer_id][key] for key in keys_to_include}\n",
      "KeyError: 'energy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL WARNING: /home/workspace/notebooks/designs/simple_weight_stationary/nerf/layer1/timeloop-mapper.stats.txt does not exist, skipping...\n",
      "CRITICAL WARNING: /home/workspace/notebooks/designs/simple_weight_stationary/nerf/layer6/timeloop-mapper.stats.txt does not exist, skipping...\n",
      "CRITICAL WARNING: /home/workspace/notebooks/designs/simple_weight_stationary/nerf/layer11/timeloop-mapper.stats.txt does not exist, skipping...\n",
      "ERROR: could not run profiler for simple_weight_stationary, do not trust these results!\n",
      "=======================================\n",
      "Running eyeriss_like_onchip_compression\n",
      "=======================================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n",
      "Sparse optimization is enabled for layer 1\n",
      "Sparse optimization is enabled for layer 2\n",
      "Sparse optimization is enabled for layer 3\n",
      "Sparse optimization is enabled for layer 4\n",
      "Sparse optimization is enabled for layer 5\n",
      "Sparse optimization is enabled for layer 6\n",
      "Sparse optimization is enabled for layer 7\n",
      "Sparse optimization is enabled for layer 8\n",
      "Sparse optimization is enabled for layer 9\n",
      "Sparse optimization is enabled for layer 10\n",
      "Sparse optimization is enabled for layer 11\n",
      "Sparse optimization is enabled for layer 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 12/12 [02:47<00:00, 13.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 804.7200000000001\n",
      "total_cycle: 1136384.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ],
   "source": [
    "# Don't use simba_like or simple_output_stationary as the mapper constraints are too stringent\n",
    "archs_and_sparse = [\n",
    "    (\"eyeriss_like\", False),\n",
    "    (\"simple_weight_stationary\", False),\n",
    "    (\"eyeriss_like_onchip_compression\", True)\n",
    "]\n",
    "failed_archs = set()\n",
    "\n",
    "for (arch, is_sparse) in archs_and_sparse:\n",
    "    msg = f\"Running {arch}\"\n",
    "    print(len(msg) * '=')\n",
    "    print(msg)\n",
    "    print(len(msg) * '=')\n",
    "    \n",
    "    # Profile - you shouldn't need to change anything here\n",
    "    try:\n",
    "        profiler = Profiler(\n",
    "            top_dir='workloads',\n",
    "            sub_dir='nerf' if not is_sparse else 'nerf-sparse',\n",
    "            timeloop_dir=f\"designs/{arch}\",\n",
    "            arch_name=arch,\n",
    "            model=model,\n",
    "            input_size=(1, 3),\n",
    "        )\n",
    "        results, summary, layer_summary = profiler.profile()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"ERROR: could not run profiler for {arch}, do not trust these results!\")\n",
    "        failed_archs.add(arch)\n",
    "        continue\n",
    "    \n",
    "    # Add nerf layer shapes to the layer summary\n",
    "    for layer_id in layer_summary:\n",
    "        layer_summary[layer_id].update(nerf_layer_shapes[layer_id])\n",
    "        \n",
    "    # Print summary information\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    profile_results[arch] = {\n",
    "        \"results\": results,\n",
    "        \"summary\": summary,\n",
    "        \"layer_summary\": layer_summary,\n",
    "    }\n",
    "    save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057b5ea",
   "metadata": {},
   "source": [
    "## Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee6177b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Massage results into dataframes\n",
    "layer_dfs = {}\n",
    "all_summary = {}\n",
    "\n",
    "for arch, arch_results in profile_results.items():\n",
    "    all_summary[arch] = arch_results[\"summary\"]\n",
    "\n",
    "    # Load layer results into dataframe\n",
    "    df_layer = pd.DataFrame.from_dict(arch_results[\"layer_summary\"], orient=\"index\")\n",
    "    df_layer = df_layer.drop('name', axis=1)\n",
    "    df_layer.index.name = \"layer_id\"\n",
    "    layer_dfs[arch] = df_layer\n",
    "    \n",
    "df_summary = pd.DataFrame.from_dict(all_summary, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf13cb",
   "metadata": {},
   "source": [
    "### Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc38df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area</th>\n",
       "      <th>total_energy</th>\n",
       "      <th>total_cycle</th>\n",
       "      <th>num_params</th>\n",
       "      <th>macs</th>\n",
       "      <th>activation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eyeriss_like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1211.45</td>\n",
       "      <td>1136384.0</td>\n",
       "      <td>595844</td>\n",
       "      <td>593450</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyeriss_like_onchip_compression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>804.72</td>\n",
       "      <td>1136384.0</td>\n",
       "      <td>595844</td>\n",
       "      <td>593450</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 total_area  total_energy  total_cycle   \n",
       "eyeriss_like                            0.0       1211.45    1136384.0  \\\n",
       "eyeriss_like_onchip_compression         0.0        804.72    1136384.0   \n",
       "\n",
       "                                 num_params    macs  activation_size  \n",
       "eyeriss_like                         595844  593450           2300.0  \n",
       "eyeriss_like_onchip_compression      595844  593450           2300.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8153f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area</th>\n",
       "      <th>total_energy</th>\n",
       "      <th>total_cycle</th>\n",
       "      <th>num</th>\n",
       "      <th>energy</th>\n",
       "      <th>area</th>\n",
       "      <th>cycle</th>\n",
       "      <th>gflops</th>\n",
       "      <th>utilization</th>\n",
       "      <th>edp</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.38</td>\n",
       "      <td>21504</td>\n",
       "      <td>1</td>\n",
       "      <td>21.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21504</td>\n",
       "      <td>190.48</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>{'C': 63, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>442.54</td>\n",
       "      <td>917504</td>\n",
       "      <td>7</td>\n",
       "      <td>63.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8.29000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>107.75</td>\n",
       "      <td>118784</td>\n",
       "      <td>1</td>\n",
       "      <td>107.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118784</td>\n",
       "      <td>175.72</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.80000</td>\n",
       "      <td>{'C': 319, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>15.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02310</td>\n",
       "      <td>{'C': 256, 'M': 1, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>631.07</td>\n",
       "      <td>72448</td>\n",
       "      <td>1</td>\n",
       "      <td>631.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72448</td>\n",
       "      <td>127.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>45.70000</td>\n",
       "      <td>{'C': 283, 'M': 128, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>47.81</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00629</td>\n",
       "      <td>{'C': 128, 'M': 3, 'N': 128}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total_area  total_energy  total_cycle  num  energy  area   cycle   \n",
       "layer_id                                                                     \n",
       "1                0.0         21.38        21504    1   21.38   0.0   21504  \\\n",
       "2                0.0        442.54       917504    7   63.22   0.0  131072   \n",
       "6                0.0        107.75       118784    1  107.75   0.0  118784   \n",
       "9                0.0          5.64         4096    1    5.64   0.0    4096   \n",
       "11               0.0        631.07        72448    1  631.07   0.0   72448   \n",
       "12               0.0          3.07         2048    1    3.07   0.0    2048   \n",
       "\n",
       "          gflops  utilization       edp                           shape  \n",
       "layer_id                                                                 \n",
       "1         190.48         0.57   0.46000   {'C': 63, 'M': 256, 'N': 128}  \n",
       "2         127.75         0.38   8.29000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "6         175.72         0.52  12.80000  {'C': 319, 'M': 256, 'N': 128}  \n",
       "9          15.97         0.05   0.02310    {'C': 256, 'M': 1, 'N': 128}  \n",
       "11        127.77         0.38  45.70000  {'C': 283, 'M': 128, 'N': 128}  \n",
       "12         47.81         0.14   0.00629    {'C': 128, 'M': 3, 'N': 128}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dfs[\"eyeriss_like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2116d617",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'simple_weight_stationary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlayer_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimple_weight_stationary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'simple_weight_stationary'"
     ]
    }
   ],
   "source": [
    "layer_dfs[\"simple_weight_stationary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e0cdfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area</th>\n",
       "      <th>total_energy</th>\n",
       "      <th>total_cycle</th>\n",
       "      <th>num</th>\n",
       "      <th>energy</th>\n",
       "      <th>area</th>\n",
       "      <th>cycle</th>\n",
       "      <th>gflops</th>\n",
       "      <th>utilization</th>\n",
       "      <th>edp</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21504</td>\n",
       "      <td>1</td>\n",
       "      <td>22.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21504</td>\n",
       "      <td>190.48</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.47500</td>\n",
       "      <td>{'C': 63, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>104.51</td>\n",
       "      <td>118784</td>\n",
       "      <td>1</td>\n",
       "      <td>104.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118784</td>\n",
       "      <td>175.72</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.40000</td>\n",
       "      <td>{'C': 319, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>15.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>{'C': 256, 'M': 1, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.59</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>80.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>127.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>{'C': 256, 'M': 256, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>106.00</td>\n",
       "      <td>72448</td>\n",
       "      <td>1</td>\n",
       "      <td>106.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72448</td>\n",
       "      <td>127.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7.68000</td>\n",
       "      <td>{'C': 283, 'M': 128, 'N': 128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>47.81</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00583</td>\n",
       "      <td>{'C': 128, 'M': 3, 'N': 128}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total_area  total_energy  total_cycle  num  energy  area   cycle   \n",
       "layer_id                                                                     \n",
       "1                0.0         22.10        21504    1   22.10   0.0   21504  \\\n",
       "2                0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "3                0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "4                0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "5                0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "6                0.0        104.51       118784    1  104.51   0.0  118784   \n",
       "7                0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "8                0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "9                0.0          5.13         4096    1    5.13   0.0    4096   \n",
       "10               0.0         80.59       131072    1   80.59   0.0  131072   \n",
       "11               0.0        106.00        72448    1  106.00   0.0   72448   \n",
       "12               0.0          2.85         2048    1    2.85   0.0    2048   \n",
       "\n",
       "          gflops  utilization       edp                           shape  \n",
       "layer_id                                                                 \n",
       "1         190.48         0.57   0.47500   {'C': 63, 'M': 256, 'N': 128}  \n",
       "2         127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "3         127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "4         127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "5         127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "6         175.72         0.52  12.40000  {'C': 319, 'M': 256, 'N': 128}  \n",
       "7         127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "8         127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "9          15.97         0.05   0.02100    {'C': 256, 'M': 1, 'N': 128}  \n",
       "10        127.75         0.38  10.60000  {'C': 256, 'M': 256, 'N': 128}  \n",
       "11        127.77         0.38   7.68000  {'C': 283, 'M': 128, 'N': 128}  \n",
       "12         47.81         0.14   0.00583    {'C': 128, 'M': 3, 'N': 128}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dfs[\"eyeriss_like_onchip_compression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
