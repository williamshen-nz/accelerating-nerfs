{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf03514d",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2577da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent dir to path so we can import accelerating_nerfs\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899904e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import traceback\n",
    "\n",
    "from collections import defaultdict\n",
    "from accelerating_nerfs.models import VanillaNeRF, patch_forward\n",
    "\n",
    "# Custom code\n",
    "from analysis import *\n",
    "from profiler import Profiler\n",
    "from notebook_utils import natural_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49e096",
   "metadata": {},
   "source": [
    "## Load NeRF model\n",
    "We use vanilla NeRFs which are MLPs. Uncomment the cell below to view the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8830c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to view architecture diagram\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(\"./figures/netdiag-modified.pdf\", width=600, height=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85925ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNeRF(\n",
      "  (posi_encoder): SinusoidalEncoder()\n",
      "  (view_encoder): SinusoidalEncoder()\n",
      "  (mlp): NerfMLP(\n",
      "    (base): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sigma_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (bottleneck_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (rgb_layer): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/models.py:254: UserWarning: patched forward of VanillaNeRF to also pass the condition. You should only use this for debugging or with Timeloop and Accelergy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VanillaNeRF()\n",
    "\n",
    "# We need to patch the forward method for the purpose of mapping to pass in ray directions\n",
    "# This ensures the bottleneck layer is captured by the converter from pytorch2timeloop \n",
    "patch_forward(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49336b",
   "metadata": {},
   "source": [
    "## Convert to Timeloop and load sparsity into the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb327e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf\n",
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf-sparse\n"
     ]
    }
   ],
   "source": [
    "# TODO: play around with the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# The unknown module type warnings are ok\n",
    "# We create a copy for nerf-sparse so we can copy the layer sparsities over to the configurations\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf\")\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf-sparse\")\n",
    "nerf_layer_shapes = load_nerf_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c895e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair_sparsity.json  hotdog_sparsity.json     mic_sparsity.json\r\n",
      "drums_sparsity.json  lego_sparsity.json       ship_sparsity.json\r\n",
      "ficus_sparsity.json  materials_sparsity.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../accelerating_nerfs/sparsity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60843261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sparsity results for dict_keys(['chair', 'drums', 'ficus', 'hotdog', 'lego', 'materials', 'mic', 'ship'])\n",
      "Layer to Average Sparsity: {\n",
      "    \"1\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 4.3946616992536214e-08,\n",
      "            \"std\": 4.918707813129488e-07,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.5542258571408987,\n",
      "            \"std\": 0.03391004992789977,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.5542258571408987,\n",
      "            \"std\": 0.03391004992789977,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6947238747829664,\n",
      "            \"std\": 0.03819135012459017,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6947238747829664,\n",
      "            \"std\": 0.03819135012459017,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.7004855604878076,\n",
      "            \"std\": 0.0401906050789546,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.7004855604878076,\n",
      "            \"std\": 0.0401906050789546,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6893779538928241,\n",
      "            \"std\": 0.0344373699693345,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6893779538928241,\n",
      "            \"std\": 0.0344373699693345,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6751321669257815,\n",
      "            \"std\": 0.04897064882230532,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.541798863641495,\n",
      "            \"std\": 0.03929933042345445,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6500948969546201,\n",
      "            \"std\": 0.04782291053415555,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6500948969546201,\n",
      "            \"std\": 0.04782291053415555,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6938947154922879,\n",
      "            \"std\": 0.060957404355100955,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6938947154922879,\n",
      "            \"std\": 0.060957404355100955,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6987572914015378,\n",
      "            \"std\": 0.037907699771396394,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6987572914015378,\n",
      "            \"std\": 0.037907699771396394,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6522592065368036,\n",
      "            \"std\": 0.3742870882921954,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6870557599287539,\n",
      "            \"std\": 0.03621108286053783,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 2.163834528961967e-09,\n",
      "            \"std\": 4.16579726744824e-08,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    },\n",
      "    \"11\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 2.4972324112363578e-09,\n",
      "            \"std\": 6.142307098905525e-08,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.7121127001079874,\n",
      "            \"std\": 0.06476021563616605,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    },\n",
      "    \"12\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.7121127001079874,\n",
      "            \"std\": 0.06476021563616605,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.0,\n",
      "            \"std\": 0.0,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load layer sparsity results\n",
    "sparsities = load_nerf_sparsities(\"../accelerating_nerfs/sparsity\")\n",
    "layer_to_avg_sparsity = compute_layer_sparsities(sparsities)\n",
    "print(\"Layer to Average Sparsity:\", json.dumps(layer_to_avg_sparsity, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af8bfc",
   "metadata": {},
   "source": [
    "### Load the sparsity results into the Timeloop layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3874398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added densities: {'Inputs': 0.999999956053383, 'Weights': 1.0, 'Outputs': 0.44577414285910133}\n",
      "Layer 2 added densities: {'Inputs': 0.44577414285910133, 'Weights': 1.0, 'Outputs': 0.3052761252170336}\n",
      "Layer 3 added densities: {'Inputs': 0.3052761252170336, 'Weights': 1.0, 'Outputs': 0.29951443951219237}\n",
      "Layer 4 added densities: {'Inputs': 0.29951443951219237, 'Weights': 1.0, 'Outputs': 0.3106220461071759}\n",
      "Layer 5 added densities: {'Inputs': 0.3106220461071759, 'Weights': 1.0, 'Outputs': 0.3248678330742185}\n",
      "Layer 6 added densities: {'Inputs': 0.458201136358505, 'Weights': 1.0, 'Outputs': 0.3499051030453799}\n",
      "Layer 7 added densities: {'Inputs': 0.3499051030453799, 'Weights': 1.0, 'Outputs': 0.3061052845077121}\n",
      "Layer 8 added densities: {'Inputs': 0.3061052845077121, 'Weights': 1.0, 'Outputs': 0.30124270859846225}\n",
      "Layer 9 added densities: {'Inputs': 0.30124270859846225, 'Weights': 1.0, 'Outputs': 0.3477407934631964}\n",
      "Layer 10 added densities: {'Inputs': 0.3129442400712461, 'Weights': 1.0, 'Outputs': 0.9999999978361654}\n",
      "Layer 11 added densities: {'Inputs': 0.9999999975027676, 'Weights': 1.0, 'Outputs': 0.28788729989201256}\n",
      "Layer 12 added densities: {'Inputs': 0.28788729989201256, 'Weights': 1.0, 'Outputs': 1.0}\n"
     ]
    }
   ],
   "source": [
    "add_sparsity_to_nerf_layers(layer_to_avg_sparsity, layer_dir=\"workloads/nerf-sparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870967",
   "metadata": {},
   "source": [
    "### Configure saving of profiling results\n",
    "This isn't important so you can ignore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41223636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results in this dictionary\n",
    "profile_results = {}\n",
    "\n",
    "# Setup saving the profiling results\n",
    "results_dir = \"profile_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    all_other_results = {}\n",
    "    \n",
    "    for arch, arch_results in profile_results.items():\n",
    "        # Write the super long results to it's own file\n",
    "        arch_results_path = os.path.join(results_dir, f\"{arch}_results.json\")\n",
    "        with open(arch_results_path, \"w\") as f:\n",
    "            json.dump(arch_results[\"results\"], f, indent=4)\n",
    "        \n",
    "        # Accumulate the other results as they're shorter and more readable\n",
    "        other_results = {\n",
    "            k: v for k, v in arch_results.items()\n",
    "            if k != \"results\"\n",
    "        }\n",
    "        # Have a pointer to the separate results file\n",
    "        other_results[\"results\"] = os.path.abspath(arch_results_path)\n",
    "        all_other_results[arch] = other_results\n",
    "    \n",
    "    results_path = os.path.join(results_dir, \"results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(all_other_results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved profile results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf13f07",
   "metadata": {},
   "source": [
    "## Profile using Timeloop and Accelergy\n",
    "I think we can safely ignore the 'No handlers found'\n",
    "\n",
    "To rerun things, delete the existing results in the `profiled_libs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4fa1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Running eyeriss_like\n",
      "====================\n",
      "timeloop-mapper /home/workspace/notebooks/designs/eyeriss_like/arch/eyeriss_like.yaml /home/workspace/notebooks/designs/eyeriss_like/arch/components/*.yaml /home/workspace/notebooks/designs/eyeriss_like/mapper/mapper.yaml /home/workspace/notebooks/designs/eyeriss_like/constraints/*.yaml /home/workspace/notebooks/workloads/nerf/nerf_layer1.yaml > /dev/null 2>&1\n",
      "timeloop-mapper /home/workspace/notebooks/designs/eyeriss_like/arch/eyeriss_like.yaml /home/workspace/notebooks/designs/eyeriss_like/arch/components/*.yaml /home/workspace/notebooks/designs/eyeriss_like/mapper/mapper.yaml /home/workspace/notebooks/designs/eyeriss_like/constraints/*.yaml /home/workspace/notebooks/workloads/nerf/nerf_layer2.yaml > /dev/null 2>&1\n",
      "timeloop-mapper /home/workspace/notebooks/designs/eyeriss_like/arch/eyeriss_like.yaml /home/workspace/notebooks/designs/eyeriss_like/arch/components/*.yaml /home/workspace/notebooks/designs/eyeriss_like/mapper/mapper.yaml /home/workspace/notebooks/designs/eyeriss_like/constraints/*.yaml /home/workspace/notebooks/workloads/nerf/nerf_layer6.yaml > /dev/null 2>&1\n",
      "timeloop-mapper /home/workspace/notebooks/designs/eyeriss_like/arch/eyeriss_like.yaml /home/workspace/notebooks/designs/eyeriss_like/arch/components/*.yaml /home/workspace/notebooks/designs/eyeriss_like/mapper/mapper.yaml /home/workspace/notebooks/designs/eyeriss_like/constraints/*.yaml /home/workspace/notebooks/workloads/nerf/nerf_layer9.yaml > /dev/null 2>&1\n",
      "timeloop-mapper /home/workspace/notebooks/designs/eyeriss_like/arch/eyeriss_like.yaml /home/workspace/notebooks/designs/eyeriss_like/arch/components/*.yaml /home/workspace/notebooks/designs/eyeriss_like/mapper/mapper.yaml /home/workspace/notebooks/designs/eyeriss_like/constraints/*.yaml /home/workspace/notebooks/workloads/nerf/nerf_layer11.yaml > /dev/null 2>&1\n",
      "timeloop-mapper /home/workspace/notebooks/designs/eyeriss_like/arch/eyeriss_like.yaml /home/workspace/notebooks/designs/eyeriss_like/arch/components/*.yaml /home/workspace/notebooks/designs/eyeriss_like/mapper/mapper.yaml /home/workspace/notebooks/designs/eyeriss_like/constraints/*.yaml /home/workspace/notebooks/workloads/nerf/nerf_layer12.yaml > /dev/null 2>&1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 6/6 [00:58<00:00,  9.77s/it]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 650.9300000000001\n",
      "total_cycle: 568192.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "=======================================\n",
      "Running eyeriss_like_onchip_compression\n",
      "=======================================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 316.71\n",
      "total_cycle: 227813.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "=============================\n",
      "Running eyeriss_like_w_gating\n",
      "=============================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_w_gating_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_w_gating_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 313.04999999999995\n",
      "total_cycle: 307611.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n"
     ]
    }
   ],
   "source": [
    "# Don't use simba_like or simple_output_stationary as the mapper constraints are too stringent\n",
    "archs_and_sparse = [\n",
    "    (\"eyeriss_like\", False),\n",
    "    # (\"simple_weight_stationary\", False),\n",
    "    (\"eyeriss_like_onchip_compression\", True),\n",
    "    (\"eyeriss_like_w_gating\", True),\n",
    "]\n",
    "failed_archs = set()\n",
    "\n",
    "for (arch, is_sparse) in archs_and_sparse:\n",
    "    msg = f\"Running {arch}\"\n",
    "    print(len(msg) * '=')\n",
    "    print(msg)\n",
    "    print(len(msg) * '=')\n",
    "    \n",
    "    # Profile - you shouldn't need to change anything here\n",
    "    try:\n",
    "        profiler = Profiler(\n",
    "            top_dir='workloads',\n",
    "            sub_dir='nerf' if not is_sparse else 'nerf-sparse',\n",
    "            timeloop_dir=f\"designs/{arch}\",\n",
    "            arch_name=arch,\n",
    "            model=model,\n",
    "            input_size=(1, 3),\n",
    "        )\n",
    "        results, summary, layer_summary = profiler.profile()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"ERROR: could not run profiler for {arch}, do not trust these results!\")\n",
    "        failed_archs.add(arch)\n",
    "        continue\n",
    "    \n",
    "    # Add nerf layer shapes to the layer summary\n",
    "    for layer_id in layer_summary:\n",
    "        layer_summary[layer_id].update(nerf_layer_shapes[layer_id])\n",
    "        \n",
    "    # Print summary information\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    profile_results[arch] = {\n",
    "        \"results\": results,\n",
    "        \"summary\": summary,\n",
    "        \"layer_summary\": layer_summary,\n",
    "    }\n",
    "    save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057b5ea",
   "metadata": {},
   "source": [
    "## Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee6177b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Massage results into dataframes\n",
    "layer_dfs = {}\n",
    "all_summary = {}\n",
    "\n",
    "for arch, arch_results in profile_results.items():\n",
    "    all_summary[arch] = arch_results[\"summary\"]\n",
    "\n",
    "    # Load layer results into dataframe\n",
    "    df_layer = pd.DataFrame.from_dict(arch_results[\"layer_summary\"], orient=\"index\")\n",
    "    df_layer = df_layer.drop('name', axis=1)\n",
    "    df_layer.index.name = \"layer_id\"\n",
    "    layer_dfs[arch] = df_layer\n",
    "    \n",
    "df_summary = pd.DataFrame.from_dict(all_summary, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf13cb",
   "metadata": {},
   "source": [
    "### Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc38df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area</th>\n",
       "      <th>total_energy</th>\n",
       "      <th>total_cycle</th>\n",
       "      <th>num_params</th>\n",
       "      <th>macs</th>\n",
       "      <th>activation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eyeriss_like_onchip_compression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>316.71</td>\n",
       "      <td>227813.0</td>\n",
       "      <td>595844</td>\n",
       "      <td>593450</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 total_area  total_energy  total_cycle   \n",
       "eyeriss_like_onchip_compression         0.0        316.71     227813.0  \\\n",
       "\n",
       "                                 num_params    macs  activation_size  \n",
       "eyeriss_like_onchip_compression      595844  593450           2300.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8153f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          total_area  total_energy  total_cycle  num  energy  area  cycle   \n",
      "layer_id                                                                    \n",
      "1                0.0         12.18        10752    1   12.18   0.0  10752  \\\n",
      "2                0.0         28.98        29215    1   28.98   0.0  29215   \n",
      "3                0.0         26.05        20007    1   26.05   0.0  20007   \n",
      "4                0.0         25.94        19629    1   25.94   0.0  19629   \n",
      "5                0.0         26.23        20357    1   26.23   0.0  20357   \n",
      "6                0.0         62.80        27214    1   62.80   0.0  27214   \n",
      "7                0.0         27.09        22932    1   27.09   0.0  22932   \n",
      "8                0.0         26.07        20061    1   26.07   0.0  20061   \n",
      "9                0.0          0.84          617    1    0.84   0.0    617   \n",
      "10               0.0         27.70        20510    1   27.70   0.0  20510   \n",
      "11               0.0         52.32        36224    1   52.32   0.0  36224   \n",
      "12               0.0          0.51          295    1    0.51   0.0    295   \n",
      "\n",
      "          gflops  utilization       edp   \n",
      "layer_id                                  \n",
      "1         191.32         0.57  0.131000  \\\n",
      "2         127.83         0.38  0.847000   \n",
      "3         127.75         0.38  0.521000   \n",
      "4         127.74         0.38  0.509000   \n",
      "5         127.74         0.38  0.534000   \n",
      "6         175.79         0.52  1.710000   \n",
      "7         127.78         0.38  0.621000   \n",
      "8         127.75         0.38  0.523000   \n",
      "9          15.96         0.05  0.000519   \n",
      "10        127.20         0.38  0.568000   \n",
      "11        127.93         0.38  1.900000   \n",
      "12         47.32         0.14  0.000149   \n",
      "\n",
      "                                                stats_fname   \n",
      "layer_id                                                      \n",
      "1         /home/workspace/notebooks/designs/eyeriss_like...  \\\n",
      "2         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "3         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "4         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "5         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "6         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "7         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "8         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "9         /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "10        /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "11        /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "12        /home/workspace/notebooks/designs/eyeriss_like...   \n",
      "\n",
      "                                  shape  \n",
      "layer_id                                 \n",
      "1          {'C': 63, 'M': 256, 'N': 64}  \n",
      "2         {'C': 256, 'M': 256, 'N': 64}  \n",
      "3         {'C': 256, 'M': 256, 'N': 64}  \n",
      "4         {'C': 256, 'M': 256, 'N': 64}  \n",
      "5         {'C': 256, 'M': 256, 'N': 64}  \n",
      "6         {'C': 319, 'M': 256, 'N': 64}  \n",
      "7         {'C': 256, 'M': 256, 'N': 64}  \n",
      "8         {'C': 256, 'M': 256, 'N': 64}  \n",
      "9           {'C': 256, 'M': 1, 'N': 64}  \n",
      "10        {'C': 256, 'M': 256, 'N': 64}  \n",
      "11        {'C': 283, 'M': 128, 'N': 64}  \n",
      "12          {'C': 128, 'M': 3, 'N': 64}  \n"
     ]
    }
   ],
   "source": [
    "print(layer_dfs[\"eyeriss_like_onchip_compression\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
