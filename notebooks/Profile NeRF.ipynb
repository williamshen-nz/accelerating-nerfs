{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf03514d",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2577da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent dir to path so we can import accelerating_nerfs\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899904e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import traceback\n",
    "\n",
    "from collections import defaultdict\n",
    "from accelerating_nerfs.models import VanillaNeRF, patch_forward\n",
    "\n",
    "# Custom code\n",
    "from analysis import *\n",
    "from profiler import Profiler\n",
    "from notebook_utils import natural_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49e096",
   "metadata": {},
   "source": [
    "## Load NeRF model\n",
    "We use vanilla NeRFs which are MLPs. Uncomment the cell below to view the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8830c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to view architecture diagram\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(\"./figures/netdiag-modified.pdf\", width=600, height=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85925ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNeRF(\n",
      "  (posi_encoder): SinusoidalEncoder()\n",
      "  (view_encoder): SinusoidalEncoder()\n",
      "  (mlp): NerfMLP(\n",
      "    (base): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sigma_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (bottleneck_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (rgb_layer): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/models.py:254: UserWarning: patched forward of VanillaNeRF to also pass the condition. You should only use this for debugging or with Timeloop and Accelergy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VanillaNeRF()\n",
    "\n",
    "# We need to patch the forward method for the purpose of mapping to pass in ray directions\n",
    "# This ensures the bottleneck layer is captured by the converter from pytorch2timeloop \n",
    "patch_forward(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49336b",
   "metadata": {},
   "source": [
    "## Convert to Timeloop and load sparsity into the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb327e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf\n",
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf-sparse\n"
     ]
    }
   ],
   "source": [
    "# TODO: play around with the batch size\n",
    "batch_size = 128\n",
    "\n",
    "# The unknown module type warnings are ok\n",
    "# We create a copy for nerf-sparse so we can copy the layer sparsities over to the configurations\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf\")\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf-sparse\")\n",
    "nerf_layer_shapes = load_nerf_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c895e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03_00-00-30_sparsity.json  2023-05-03_18-13-41_volrend_sparsity.json\r\n",
      "2023-05-03_00-21-28_sparsity.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../accelerating_nerfs/sparsity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60843261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sparsity results for dict_keys(['chair', 'drums', 'ficus', 'hotdog', 'lego', 'materials', 'mic', 'ship'])\n",
      "Layer to Average Sparsity: {\n",
      "    \"1\": 4.346944171693548e-08,\n",
      "    \"2\": 0.5232157788498581,\n",
      "    \"3\": 0.6606506746276803,\n",
      "    \"4\": 0.6719614964550145,\n",
      "    \"5\": 0.635327070883858,\n",
      "    \"6\": 0.49655377627334907,\n",
      "    \"7\": 0.5577130213002062,\n",
      "    \"8\": 0.6088893305723659,\n",
      "    \"9\": 0.5989934303659363,\n",
      "    \"10\": 0.5785213852133457,\n",
      "    \"11\": 2.1946953467908288e-09,\n",
      "    \"12\": 0.6979629018407192\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load layer sparsity results\n",
    "sparsities = load_nerf_sparsities(\"../accelerating_nerfs/sparsity/2023-05-03_00-21-28_sparsity.json\")\n",
    "layer_to_avg_sparsity = compute_layer_sparsities(sparsities)\n",
    "print(\"Layer to Average Sparsity:\", json.dumps(layer_to_avg_sparsity, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af8bfc",
   "metadata": {},
   "source": [
    "### Load the sparsity results into the Timeloop layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3874398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added densities: {'Inputs': 0.9999999565305583, 'Weights': 1.0, 'Outputs': 0.9999999565305583}\n",
      "Layer 2 added densities: {'Inputs': 0.47678422115014185, 'Weights': 1.0, 'Outputs': 0.47678422115014185}\n",
      "Layer 3 added densities: {'Inputs': 0.33934932537231965, 'Weights': 1.0, 'Outputs': 0.33934932537231965}\n",
      "Layer 4 added densities: {'Inputs': 0.32803850354498554, 'Weights': 1.0, 'Outputs': 0.32803850354498554}\n",
      "Layer 5 added densities: {'Inputs': 0.364672929116142, 'Weights': 1.0, 'Outputs': 0.364672929116142}\n",
      "Layer 6 added densities: {'Inputs': 0.5034462237266509, 'Weights': 1.0, 'Outputs': 0.5034462237266509}\n",
      "Layer 7 added densities: {'Inputs': 0.44228697869979383, 'Weights': 1.0, 'Outputs': 0.44228697869979383}\n",
      "Layer 8 added densities: {'Inputs': 0.39111066942763406, 'Weights': 1.0, 'Outputs': 0.39111066942763406}\n",
      "Layer 9 added densities: {'Inputs': 0.40100656963406367, 'Weights': 1.0, 'Outputs': 0.40100656963406367}\n",
      "Layer 10 added densities: {'Inputs': 0.42147861478665427, 'Weights': 1.0, 'Outputs': 0.42147861478665427}\n",
      "Layer 11 added densities: {'Inputs': 0.9999999978053047, 'Weights': 1.0, 'Outputs': 0.9999999978053047}\n",
      "Layer 12 added densities: {'Inputs': 0.3020370981592808, 'Weights': 1.0, 'Outputs': 0.3020370981592808}\n"
     ]
    }
   ],
   "source": [
    "add_sparsity_to_nerf_layers(layer_to_avg_sparsity, layer_dir=\"workloads/nerf-sparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870967",
   "metadata": {},
   "source": [
    "### Configure saving of profiling results\n",
    "This isn't important so you can ignore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41223636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results in this dictionary\n",
    "profile_results = {}\n",
    "\n",
    "# Setup saving the profiling results\n",
    "results_dir = \"profile_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    all_other_results = {}\n",
    "    \n",
    "    for arch, arch_results in profile_results.items():\n",
    "        # Write the super long results to it's own file\n",
    "        arch_results_path = os.path.join(results_dir, f\"{arch}_results.json\")\n",
    "        with open(arch_results_path, \"w\") as f:\n",
    "            json.dump(arch_results[\"results\"], f, indent=4)\n",
    "        \n",
    "        # Accumulate the other results as they're shorter and more readable\n",
    "        other_results = {\n",
    "            k: v for k, v in arch_results.items()\n",
    "            if k != \"results\"\n",
    "        }\n",
    "        # Have a pointer to the separate results file\n",
    "        other_results[\"results\"] = os.path.abspath(arch_results_path)\n",
    "        all_other_results[arch] = other_results\n",
    "    \n",
    "    results_path = os.path.join(results_dir, \"results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(all_other_results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved profile results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf13f07",
   "metadata": {},
   "source": [
    "## Profile using Timeloop and Accelergy\n",
    "I think we can safely ignore the 'No handlers found'\n",
    "\n",
    "To rerun things, delete the existing results in the `profiled_libs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fa1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Running eyeriss_like\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 6/6 [01:05<00:00, 10.93s/it]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 1211.45\n",
      "total_cycle: 1136384.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "================================\n",
      "Running simple_weight_stationary\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 6/6 [03:39<00:00, 36.50s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_796/3037256322.py\", line 25, in <module>\n",
      "    results, summary, layer_summary = profiler.profile()\n",
      "  File \"/home/workspace/notebooks/profiler.py\", line 348, in profile\n",
      "    self.populate_profiled_lib(layer_info)\n",
      "  File \"/home/workspace/notebooks/profiler.py\", line 297, in populate_profiled_lib\n",
      "    info = {key: layer_info[layer_id][key] for key in keys_to_include}\n",
      "  File \"/home/workspace/notebooks/profiler.py\", line 297, in <dictcomp>\n",
      "    info = {key: layer_info[layer_id][key] for key in keys_to_include}\n",
      "KeyError: 'energy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL WARNING: /home/workspace/notebooks/designs/simple_weight_stationary/nerf/layer1/timeloop-mapper.stats.txt does not exist, skipping...\n",
      "CRITICAL WARNING: /home/workspace/notebooks/designs/simple_weight_stationary/nerf/layer6/timeloop-mapper.stats.txt does not exist, skipping...\n",
      "CRITICAL WARNING: /home/workspace/notebooks/designs/simple_weight_stationary/nerf/layer11/timeloop-mapper.stats.txt does not exist, skipping...\n",
      "ERROR: could not run profiler for simple_weight_stationary, do not trust these results!\n",
      "=======================================\n",
      "Running eyeriss_like_onchip_compression\n",
      "=======================================\n",
      "Sparse optimization is enabled for layer 1\n",
      "Sparse optimization is enabled for layer 2\n",
      "Sparse optimization is enabled for layer 3\n",
      "Sparse optimization is enabled for layer 4\n",
      "Sparse optimization is enabled for layer 5\n",
      "Sparse optimization is enabled for layer 6\n",
      "Sparse optimization is enabled for layer 7\n",
      "Sparse optimization is enabled for layer 8\n",
      "Sparse optimization is enabled for layer 9\n",
      "Sparse optimization is enabled for layer 10\n",
      "Sparse optimization is enabled for layer 11\n",
      "Sparse optimization is enabled for layer 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...:  33%|███▎      | 4/12 [00:37<01:19,  9.98s/it]"
     ]
    }
   ],
   "source": [
    "# Don't use simba_like or simple_output_stationary as the mapper constraints are too stringent\n",
    "archs_and_sparse = [\n",
    "    (\"eyeriss_like\", False),\n",
    "    (\"simple_weight_stationary\", False),\n",
    "    (\"eyeriss_like_onchip_compression\", True)\n",
    "]\n",
    "failed_archs = set()\n",
    "\n",
    "for (arch, is_sparse) in archs_and_sparse:\n",
    "    msg = f\"Running {arch}\"\n",
    "    print(len(msg) * '=')\n",
    "    print(msg)\n",
    "    print(len(msg) * '=')\n",
    "    \n",
    "    # Profile - you shouldn't need to change anything here\n",
    "    try:\n",
    "        profiler = Profiler(\n",
    "            top_dir='workloads',\n",
    "            sub_dir='nerf' if not is_sparse else 'nerf-sparse',\n",
    "            timeloop_dir=f\"designs/{arch}\",\n",
    "            arch_name=arch,\n",
    "            model=model,\n",
    "            input_size=(1, 3),\n",
    "        )\n",
    "        results, summary, layer_summary = profiler.profile()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"ERROR: could not run profiler for {arch}, do not trust these results!\")\n",
    "        failed_archs.add(arch)\n",
    "        continue\n",
    "    \n",
    "    # Add nerf layer shapes to the layer summary\n",
    "    for layer_id in layer_summary:\n",
    "        layer_summary[layer_id].update(nerf_layer_shapes[layer_id])\n",
    "        \n",
    "    # Print summary information\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    profile_results[arch] = {\n",
    "        \"results\": results,\n",
    "        \"summary\": summary,\n",
    "        \"layer_summary\": layer_summary,\n",
    "    }\n",
    "    save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7a1c7",
   "metadata": {},
   "source": [
    "## Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6177b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Massage results into dataframes\n",
    "layer_dfs = {}\n",
    "all_summary = {}\n",
    "\n",
    "for arch, arch_results in profile_results.items():\n",
    "    all_summary[arch] = arch_results[\"summary\"]\n",
    "\n",
    "    # Load layer results into dataframe\n",
    "    df_layer = pd.DataFrame.from_dict(arch_results[\"layer_summary\"], orient=\"index\")\n",
    "    df_layer = df_layer.drop('name', axis=1)\n",
    "    df_layer.index.name = \"layer_id\"\n",
    "    layer_dfs[arch] = df_layer\n",
    "    \n",
    "df_summary = pd.DataFrame.from_dict(all_summary, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53754954",
   "metadata": {},
   "source": [
    "### Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52660ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28219ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dfs[\"eyeriss_like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dfs[\"simple_weight_stationary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dfs[\"eyeriss_like_onchip_compression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d52b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
