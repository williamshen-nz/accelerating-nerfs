{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf03514d",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2577da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent dir to path so we can import accelerating_nerfs\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899904e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIN COUNT 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/discretize_positional_enc.py:9: UserWarning: Failed to initialize NumPy: module compiled against API version 0xf but this version of numpy is 0xe (Triggered internally at /root/pytorch/torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import traceback\n",
    "\n",
    "from collections import defaultdict\n",
    "from accelerating_nerfs.models import VanillaNeRF, patch_forward\n",
    "\n",
    "# Custom code\n",
    "from analysis import *\n",
    "from profiler import Profiler\n",
    "from notebook_utils import natural_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49e096",
   "metadata": {},
   "source": [
    "## Load NeRF model\n",
    "We use vanilla NeRFs which are MLPs. Uncomment the cell below to view the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8830c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to view architecture diagram\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(\"./figures/netdiag-modified.pdf\", width=600, height=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85925ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNeRF(\n",
      "  (posi_encoder): SinusoidalEncoder()\n",
      "  (view_encoder): SinusoidalEncoder()\n",
      "  (mlp): NerfMLP(\n",
      "    (base): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sigma_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (bottleneck_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (rgb_layer): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/models.py:262: UserWarning: patched forward of VanillaNeRF to also pass the condition. You should only use this for debugging or with Timeloop and Accelergy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VanillaNeRF()\n",
    "\n",
    "# We need to patch the forward method for the purpose of mapping to pass in ray directions\n",
    "# This ensures the bottleneck layer is captured by the converter from pytorch2timeloop \n",
    "patch_forward(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49336b",
   "metadata": {},
   "source": [
    "## Convert to Timeloop and load sparsity into the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb327e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf\n",
      "Converted VanillaNeRF model to Timeloop problems in workloads/nerf-sparse\n"
     ]
    }
   ],
   "source": [
    "# TODO: play around with the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# The unknown module type warnings are ok\n",
    "# We create a copy for nerf-sparse so we can copy the layer sparsities over to the configurations\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf\")\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=batch_size, sub_dir=\"nerf-sparse\")\n",
    "nerf_layer_shapes = load_nerf_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c895e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair_sparsity.json  hotdog_sparsity.json     mic_sparsity.json\r\n",
      "drums_sparsity.json  lego_sparsity.json       ship_sparsity.json\r\n",
      "ficus_sparsity.json  materials_sparsity.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../accelerating_nerfs/sparsity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60843261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sparsity results for dict_keys(['chair', 'drums', 'ficus', 'hotdog', 'lego', 'materials', 'mic', 'ship'])\n",
      "Layer to Average Sparsity: {\n",
      "    \"1\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 4.3946616992536214e-08,\n",
      "            \"std\": 4.918707813129488e-07,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.5542258571408987,\n",
      "            \"std\": 0.03391004992789977,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.5542258571408987,\n",
      "            \"std\": 0.03391004992789977,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6947238747829664,\n",
      "            \"std\": 0.03819135012459017,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6947238747829664,\n",
      "            \"std\": 0.03819135012459017,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.7004855604878076,\n",
      "            \"std\": 0.0401906050789546,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.7004855604878076,\n",
      "            \"std\": 0.0401906050789546,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6893779538928241,\n",
      "            \"std\": 0.0344373699693345,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6893779538928241,\n",
      "            \"std\": 0.0344373699693345,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6751321669257815,\n",
      "            \"std\": 0.04897064882230532,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.541798863641495,\n",
      "            \"std\": 0.03929933042345445,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6500948969546201,\n",
      "            \"std\": 0.04782291053415555,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6500948969546201,\n",
      "            \"std\": 0.04782291053415555,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6938947154922879,\n",
      "            \"std\": 0.060957404355100955,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6938947154922879,\n",
      "            \"std\": 0.060957404355100955,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6987572914015378,\n",
      "            \"std\": 0.037907699771396394,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6987572914015378,\n",
      "            \"std\": 0.037907699771396394,\n",
      "            \"num\": 27708\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.6522592065368036,\n",
      "            \"std\": 0.3742870882921954,\n",
      "            \"num\": 27708\n",
      "        }\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.6870557599287539,\n",
      "            \"std\": 0.03621108286053783,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 2.163834528961967e-09,\n",
      "            \"std\": 4.16579726744824e-08,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    },\n",
      "    \"11\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 2.4972324112363578e-09,\n",
      "            \"std\": 6.142307098905525e-08,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.7121127001079874,\n",
      "            \"std\": 0.06476021563616605,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    },\n",
      "    \"12\": {\n",
      "        \"input_sparsity\": {\n",
      "            \"mean\": 0.7121127001079874,\n",
      "            \"std\": 0.06476021563616605,\n",
      "            \"num\": 13854\n",
      "        },\n",
      "        \"output_sparsity\": {\n",
      "            \"mean\": 0.0,\n",
      "            \"std\": 0.0,\n",
      "            \"num\": 13854\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load layer sparsity results\n",
    "sparsities = load_nerf_sparsities(\"../accelerating_nerfs/sparsity\")\n",
    "layer_to_avg_sparsity = compute_layer_sparsities(sparsities)\n",
    "print(\"Layer to Average Sparsity:\", json.dumps(layer_to_avg_sparsity, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af8bfc",
   "metadata": {},
   "source": [
    "### Load the sparsity results into the Timeloop layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3874398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added densities: {'Inputs': 0.999999956053383, 'Weights': 1.0, 'Outputs': 0.44577414285910133}\n",
      "Layer 2 added densities: {'Inputs': 0.44577414285910133, 'Weights': 1.0, 'Outputs': 0.3052761252170336}\n",
      "Layer 3 added densities: {'Inputs': 0.3052761252170336, 'Weights': 1.0, 'Outputs': 0.29951443951219237}\n",
      "Layer 4 added densities: {'Inputs': 0.29951443951219237, 'Weights': 1.0, 'Outputs': 0.3106220461071759}\n",
      "Layer 5 added densities: {'Inputs': 0.3106220461071759, 'Weights': 1.0, 'Outputs': 0.3248678330742185}\n",
      "Layer 6 added densities: {'Inputs': 0.458201136358505, 'Weights': 1.0, 'Outputs': 0.3499051030453799}\n",
      "Layer 7 added densities: {'Inputs': 0.3499051030453799, 'Weights': 1.0, 'Outputs': 0.3061052845077121}\n",
      "Layer 8 added densities: {'Inputs': 0.3061052845077121, 'Weights': 1.0, 'Outputs': 0.30124270859846225}\n",
      "Layer 9 added densities: {'Inputs': 0.30124270859846225, 'Weights': 1.0, 'Outputs': 0.3477407934631964}\n",
      "Layer 10 added densities: {'Inputs': 0.3129442400712461, 'Weights': 1.0, 'Outputs': 0.9999999978361654}\n",
      "Layer 11 added densities: {'Inputs': 0.9999999975027676, 'Weights': 1.0, 'Outputs': 0.28788729989201256}\n",
      "Layer 12 added densities: {'Inputs': 0.28788729989201256, 'Weights': 1.0, 'Outputs': 1.0}\n"
     ]
    }
   ],
   "source": [
    "add_sparsity_to_nerf_layers(layer_to_avg_sparsity, layer_dir=\"workloads/nerf-sparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870967",
   "metadata": {},
   "source": [
    "### Configure saving of profiling results\n",
    "This isn't important so you can ignore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41223636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results in this dictionary\n",
    "profile_results = {}\n",
    "\n",
    "# Setup saving the profiling results\n",
    "results_dir = \"profile_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    all_other_results = {}\n",
    "    \n",
    "    for arch, arch_results in profile_results.items():\n",
    "        # Write the super long results to it's own file\n",
    "        arch_results_path = os.path.join(results_dir, f\"{arch}_results.json\")\n",
    "        with open(arch_results_path, \"w\") as f:\n",
    "            json.dump(arch_results[\"results\"], f, indent=4)\n",
    "        \n",
    "        # Accumulate the other results as they're shorter and more readable\n",
    "        other_results = {\n",
    "            k: v for k, v in arch_results.items()\n",
    "            if k != \"results\"\n",
    "        }\n",
    "        # Have a pointer to the separate results file\n",
    "        other_results[\"results\"] = os.path.abspath(arch_results_path)\n",
    "        all_other_results[arch] = other_results\n",
    "    \n",
    "    results_path = os.path.join(results_dir, \"results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(all_other_results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved profile results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf13f07",
   "metadata": {},
   "source": [
    "## Profile using Timeloop and Accelergy\n",
    "I think we can safely ignore the 'No handlers found'\n",
    "\n",
    "To rerun things, delete the existing results in the `profiled_libs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4fa1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Running eyeriss_like\n",
      "====================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 650.9300000000001\n",
      "total_cycle: 568192.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "=========================================\n",
      "Running eyeriss_like_glb_compression_only\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse optimization enabled for layer 1\n",
      "Sparse optimization enabled for layer 2\n",
      "Sparse optimization enabled for layer 3\n",
      "Sparse optimization enabled for layer 4\n",
      "Sparse optimization enabled for layer 5\n",
      "Sparse optimization enabled for layer 6\n",
      "Sparse optimization enabled for layer 7\n",
      "Sparse optimization enabled for layer 8\n",
      "Sparse optimization enabled for layer 9\n",
      "Sparse optimization enabled for layer 10\n",
      "Sparse optimization enabled for layer 11\n",
      "Sparse optimization enabled for layer 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 12/12 [02:39<00:00, 13.28s/it]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_glb_compression_only_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 364.87999999999994\n",
      "total_cycle: 568192.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "============================================\n",
      "Running eyeriss_like_onchip_compression_only\n",
      "============================================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_onchip_compression_only_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_onchip_compression_only_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 364.87999999999994\n",
      "total_cycle: 568192.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "=======================================\n",
      "Running eyeriss_like_onchip_compression\n",
      "=======================================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 316.71\n",
      "total_cycle: 227813.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n",
      "=============================\n",
      "Running eyeriss_like_w_gating\n",
      "=============================\n",
      "Loaded profiled lib from ./profiled_libs/eyeriss_like_w_gating_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./profiled_libs/eyeriss_like_w_gating_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 313.04999999999995\n",
      "total_cycle: 307611.0\n",
      "num_params: 595844\n",
      "macs: 593450\n",
      "activation_size: 2300.0\n",
      "Saved profile results to profile_results/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ],
   "source": [
    "# Don't use simba_like or simple_output_stationary as the mapper constraints are too stringent\n",
    "archs_and_sparse = [\n",
    "    (\"eyeriss_like\", False),\n",
    "    (\"eyeriss_like_glb_compression_only\", True),  # without skipping\n",
    "    (\"eyeriss_like_onchip_compression_only\", True),  # without skipping\n",
    "    (\"eyeriss_like_onchip_compression\", True),  # with skipping\n",
    "    (\"eyeriss_like_w_gating\", True),  # gating\n",
    "]\n",
    "failed_archs = set()\n",
    "\n",
    "for (arch, is_sparse) in archs_and_sparse:\n",
    "    msg = f\"Running {arch}\"\n",
    "    print(len(msg) * '=')\n",
    "    print(msg)\n",
    "    print(len(msg) * '=')\n",
    "    \n",
    "    # Profile - you shouldn't need to change anything here\n",
    "    try:\n",
    "        profiler = Profiler(\n",
    "            top_dir='workloads',\n",
    "            sub_dir='nerf' if not is_sparse else 'nerf-sparse',\n",
    "            timeloop_dir=f\"designs/{arch}\",\n",
    "            arch_name=arch,\n",
    "            model=model,\n",
    "            input_size=(1, 3),\n",
    "        )\n",
    "        results, summary, layer_summary = profiler.profile()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"ERROR: could not run profiler for {arch}, do not trust these results!\")\n",
    "        failed_archs.add(arch)\n",
    "        continue\n",
    "    \n",
    "    # Add nerf layer shapes to the layer summary\n",
    "    for layer_id in layer_summary:\n",
    "        layer_summary[layer_id].update(nerf_layer_shapes[layer_id])\n",
    "        \n",
    "    # Print summary information\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    profile_results[arch] = {\n",
    "        \"results\": results,\n",
    "        \"summary\": summary,\n",
    "        \"layer_summary\": layer_summary,\n",
    "    }\n",
    "    save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057b5ea",
   "metadata": {},
   "source": [
    "### <span style=\"color: red\">Analyze detailed results in \"Analyze Results.ipynb\"</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
