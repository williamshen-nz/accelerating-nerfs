{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b46cecc",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46365808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from profiler import Profiler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "from accelerating_nerfs.models import VanillaNeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb902ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNeRF(\n",
      "  (posi_encoder): SinusoidalEncoder()\n",
      "  (view_encoder): SinusoidalEncoder()\n",
      "  (mlp): NerfMLP(\n",
      "    (base): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sigma_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (bottleneck_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (rgb_layer): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Using vanilla NeRF which are MLPs\n",
    "model = VanillaNeRF()\n",
    "\n",
    "# Need to patch the forward method for the purpose of mapping to pass in ray directions\n",
    "# This ensures the bottleneck layer is captured in the timeloop outputs\n",
    "model.old_forward = model.forward\n",
    "\n",
    "def new_forward(self, x):\n",
    "    return self.old_forward(x, x)\n",
    "\n",
    "model.forward = new_forward.__get__(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93339c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeloop running finished!\n",
      "{'total_energy': 421708.64999999997, 'total_cycle': 725352448, 'num_params': 595844, 'macs': 593450, 'activation_size': 2300.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ],
   "source": [
    "profiler = Profiler(\n",
    "    top_dir='workloads',\n",
    "    sub_dir='nerf',\n",
    "    timeloop_dir='simple_weight_stationary',\n",
    "    model=model,\n",
    "    input_size=(1, 3),\n",
    "    batch_size=2 ** 14,\n",
    "    convert_fc=True,\n",
    "    exception_module_names=[]\n",
    ")\n",
    "\n",
    "results, summary = profiler.profile()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e93dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1 \t Energy: 5172.87 \t Cycle: 7340032 \t Number of same architecture layers: 1\n",
      "ID: 2 \t Energy: 47639.28 \t Cycle: 33554432 \t Number of same architecture layers: 7\n",
      "ID: 6 \t Energy: 52584.33 \t Cycle: 334495744 \t Number of same architecture layers: 1\n",
      "ID: 9 \t Energy: 579.42 \t Cycle: 131072 \t Number of same architecture layers: 1\n",
      "ID: 11 \t Energy: 29561.67 \t Cycle: 148373504 \t Number of same architecture layers: 1\n",
      "ID: 12 \t Energy: 335.4 \t Cycle: 131072 \t Number of same architecture layers: 1\n",
      "\n",
      "Total Energy: 421708.64999999997 uj \n",
      "Total Cycles: 725352448\n"
     ]
    }
   ],
   "source": [
    "total_energy = 0\n",
    "total_cycle = 0\n",
    "\n",
    "for layer_id, info in results.items():\n",
    "    print(f\"ID: {layer_id} \\t Energy: {info['energy']} \\t Cycle: {info['cycle']} \\t Number of same architecture layers: {info['num']}\")\n",
    "    total_energy += info['energy'] * info['num']\n",
    "    total_cycle += info['cycle'] * info['num']\n",
    "    \n",
    "print(f'\\nTotal Energy: {total_energy} uj \\nTotal Cycles: {total_cycle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1a013a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nerf_layer1.yaml, C=63, M=256, N=16384\n",
      "nerf_layer2.yaml, C=256, M=256, N=16384\n",
      "nerf_layer3.yaml, C=256, M=256, N=16384\n",
      "nerf_layer4.yaml, C=256, M=256, N=16384\n",
      "nerf_layer5.yaml, C=256, M=256, N=16384\n",
      "nerf_layer6.yaml, C=319, M=256, N=16384\n",
      "nerf_layer7.yaml, C=256, M=256, N=16384\n",
      "nerf_layer8.yaml, C=256, M=256, N=16384\n",
      "nerf_layer9.yaml, C=256, M=1, N=16384\n",
      "nerf_layer10.yaml, C=256, M=256, N=16384\n",
      "nerf_layer11.yaml, C=283, M=128, N=16384\n",
      "nerf_layer12.yaml, C=128, M=3, N=16384\n"
     ]
    }
   ],
   "source": [
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "nerf_layer_dir = \"workloads/nerf\"\n",
    "for layer_path in natural_sort(os.listdir(nerf_layer_dir)):\n",
    "    layer_path = os.path.join(nerf_layer_dir, layer_path)\n",
    "    \n",
    "    with open(layer_path, \"r\") as f:\n",
    "        layer_config = yaml.safe_load(f)\n",
    "        \n",
    "    C = layer_config['problem']['instance']['C']\n",
    "    M = layer_config['problem']['instance']['M']\n",
    "    N = layer_config['problem']['instance']['N']\n",
    "    print(f\"{os.path.basename(layer_path)}, C={C}, M={M}, N={N}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
