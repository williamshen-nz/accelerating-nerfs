{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf03514d",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9a3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent dir to path so we can import accelerating_nerfs\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899904e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import traceback\n",
    "\n",
    "from collections import defaultdict\n",
    "from accelerating_nerfs.models import VanillaNeRF, patch_forward\n",
    "\n",
    "# Custom code\n",
    "from analysis import *\n",
    "from profiler import Profiler\n",
    "from notebook_utils import natural_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49e096",
   "metadata": {},
   "source": [
    "## Load NeRF model\n",
    "We use vanilla NeRFs which are MLPs. Uncomment the cell below to view the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8830c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to view architecture diagram\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(\"./figures/netdiag-modified.pdf\", width=600, height=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85925ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaNeRF(\n",
      "  (posi_encoder): SinusoidalEncoder()\n",
      "  (view_encoder): SinusoidalEncoder()\n",
      "  (mlp): NerfMLP(\n",
      "    (base): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sigma_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (bottleneck_layer): DenseLayer(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList()\n",
      "      (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (rgb_layer): MLP(\n",
      "      (hidden_activation): ReLU()\n",
      "      (output_activation): Identity()\n",
      "      (hidden_layers): ModuleList(\n",
      "        (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/models.py:254: UserWarning: patched forward of VanillaNeRF to also pass the condition. You should only use this for debugging or with Timeloop and Accelergy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VanillaNeRF()\n",
    "\n",
    "# We need to patch the forward method for the purpose of mapping to pass in ray directions\n",
    "# This ensures the bottleneck layer is captured by the converter from pytorch2timeloop \n",
    "patch_forward(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061113d6",
   "metadata": {},
   "source": [
    "## Convert to Timeloop and load sparsity into the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a8497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'accelerating_nerfs.models.SinusoidalEncoder'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.DenseLayer'>\n",
      "unknown module type <class 'torch.nn.modules.linear.Identity'>\n",
      "unknown module type <class 'accelerating_nerfs.models.MLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.NerfMLP'>\n",
      "unknown module type <class 'accelerating_nerfs.models.VanillaNeRF'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted VanillaNeRF model to Timeloop problems in workload/nerf\n"
     ]
    }
   ],
   "source": [
    "# TODO: play around with the batch size\n",
    "# The unknown module type warnings are ok\n",
    "_ = convert_nerf_to_timeloop(model, batch_size=128)\n",
    "nerf_layer_shapes = load_nerf_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2780d150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03_00-00-30_sparsity.json  2023-05-03_18-13-41_volrend_sparsity.json\r\n",
      "2023-05-03_00-21-28_sparsity.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../accelerating_nerfs/sparsity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666e6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sparsity results for dict_keys(['chair', 'drums', 'ficus', 'hotdog', 'lego', 'materials', 'mic', 'ship'])\n",
      "Layer to Average Sparsity: {\n",
      "    \"1\": 4.346944171693548e-08,\n",
      "    \"2\": 0.5232157788498581,\n",
      "    \"3\": 0.6606506746276803,\n",
      "    \"4\": 0.6719614964550145,\n",
      "    \"5\": 0.635327070883858,\n",
      "    \"6\": 0.49655377627334907,\n",
      "    \"7\": 0.5577130213002062,\n",
      "    \"8\": 0.6088893305723659,\n",
      "    \"9\": 0.5989934303659363,\n",
      "    \"10\": 0.5785213852133457,\n",
      "    \"11\": 2.1946953467908288e-09,\n",
      "    \"12\": 0.6979629018407192\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sparsities = load_nerf_sparsities(\"../accelerating_nerfs/sparsity/2023-05-03_00-21-28_sparsity.json\")\n",
    "layer_to_avg_sparsity = compute_layer_sparsities(sparsities)\n",
    "print(\"Layer to Average Sparsity:\", json.dumps(layer_to_avg_sparsity, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a6f7d",
   "metadata": {},
   "source": [
    "### Load the sparsity results into the Timeloop layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee8c03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added densities: {'Inputs': 0.9999999565305583, 'Weights': 1.0, 'Outputs': 0.9999999565305583}\n",
      "Layer 2 added densities: {'Inputs': 0.47678422115014185, 'Weights': 1.0, 'Outputs': 0.47678422115014185}\n",
      "Layer 3 added densities: {'Inputs': 0.33934932537231965, 'Weights': 1.0, 'Outputs': 0.33934932537231965}\n",
      "Layer 4 added densities: {'Inputs': 0.32803850354498554, 'Weights': 1.0, 'Outputs': 0.32803850354498554}\n",
      "Layer 5 added densities: {'Inputs': 0.364672929116142, 'Weights': 1.0, 'Outputs': 0.364672929116142}\n",
      "Layer 6 added densities: {'Inputs': 0.5034462237266509, 'Weights': 1.0, 'Outputs': 0.5034462237266509}\n",
      "Layer 7 added densities: {'Inputs': 0.44228697869979383, 'Weights': 1.0, 'Outputs': 0.44228697869979383}\n",
      "Layer 8 added densities: {'Inputs': 0.39111066942763406, 'Weights': 1.0, 'Outputs': 0.39111066942763406}\n",
      "Layer 9 added densities: {'Inputs': 0.40100656963406367, 'Weights': 1.0, 'Outputs': 0.40100656963406367}\n",
      "Layer 10 added densities: {'Inputs': 0.42147861478665427, 'Weights': 1.0, 'Outputs': 0.42147861478665427}\n",
      "Layer 11 added densities: {'Inputs': 0.9999999978053047, 'Weights': 1.0, 'Outputs': 0.9999999978053047}\n",
      "Layer 12 added densities: {'Inputs': 0.3020370981592808, 'Weights': 1.0, 'Outputs': 0.3020370981592808}\n"
     ]
    }
   ],
   "source": [
    "add_sparsity_to_nerf_layers(layer_to_avg_sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115afd41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870967",
   "metadata": {},
   "source": [
    "### Configure saving of profiling results\n",
    "This isn't important so you can ignore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41223636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results in this dictionary\n",
    "profile_results = {}\n",
    "\n",
    "# Setup saving the profiling results\n",
    "results_dir = \"profile_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    all_other_results = {}\n",
    "    \n",
    "    for arch, arch_results in profile_results.items():\n",
    "        # Write the super long results to it's own file\n",
    "        arch_results_path = os.path.join(results_dir, f\"{arch}_results.json\")\n",
    "        with open(arch_results_path, \"w\") as f:\n",
    "            json.dump(arch_results[\"results\"], f, indent=4)\n",
    "            print(f\"Saved {arch} results to {arch_results_path}\")\n",
    "        \n",
    "        # Accumulate the other results as they're shorter and more readable\n",
    "        other_results = {\n",
    "            k: v for k, v in arch_results.items()\n",
    "            if k != \"results\"\n",
    "        }\n",
    "        # Have a pointer to the separate results file\n",
    "        other_results[\"results\"] = os.path.abspath(arch_results_path)\n",
    "        all_other_results[arch] = other_results\n",
    "    \n",
    "    results_path = os.path.join(results_dir, \"results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(all_other_results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved profile results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33fd4d",
   "metadata": {},
   "source": [
    "### Loading NeRF layer shapes\n",
    "You can ignore this, it's for populating the profiling results with additional debug information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e12e0d",
   "metadata": {},
   "source": [
    "### Add densities to NeRF layer problems\n",
    "Load the layer sparsities from our earlier analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf13f07",
   "metadata": {},
   "source": [
    "## Profile using Timeloop and Accelergy\n",
    "I think we can safely ignore the 'unknown module type' warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fa1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Don't use simba_like or simple_output_stationary as the mapper constraints are too stringent\n",
    "# archs = [\"eyeriss_like\", \"simba_like_modified\", \"simple_output_stationary_modified\", \"simple_weight_stationary\"]\n",
    "# archs = [\"simba_like_modified\", \"simple_output_stationary_modified\"]\n",
    "archs = [\"eyeriss_like_onchip_compression\"]\n",
    "failed_archs = set()\n",
    "\n",
    "for arch in archs:\n",
    "    print(20 * '=')\n",
    "    print(f\"Running {arch}\")\n",
    "    print(20 * '=')\n",
    "    \n",
    "    # Profile - you should only need to change batch_size if anything\n",
    "    try:\n",
    "        profiler = Profiler(\n",
    "            top_dir='workloads',\n",
    "            sub_dir='nerf',\n",
    "            timeloop_dir=f\"designs/{arch}\",\n",
    "            arch_name=arch,\n",
    "            model=model,\n",
    "            input_size=(1, 3),\n",
    "            batch_size=128,  # TODO: adjust this, ICARUS uses 128\n",
    "            convert_fc=True,\n",
    "            exception_module_names=[]\n",
    "        )\n",
    "        add_density_to_nerf_layers()\n",
    "        results, summary, layer_summary = profiler.profile()\n",
    "    except Exception as e:\n",
    "        # TODO: figure this out https://piazza.com/class/ldf2iof72w51sl/post/44\n",
    "        traceback.print_exc()\n",
    "        print(f\"ERROR: could not run profiler for {arch}, do not trust these results!\")\n",
    "        failed_archs.add(arch)\n",
    "        continue\n",
    "    \n",
    "    # Add nerf layer shapes to the layer summary\n",
    "    for layer_id in layer_summary:\n",
    "        layer_summary[layer_id].update(nerf_layer_shapes()[layer_id])\n",
    "        \n",
    "    # Print summary information\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    profile_results[arch] = {\n",
    "        \"results\": results,\n",
    "        \"summary\": summary,\n",
    "        \"layer_summary\": layer_summary,\n",
    "    }\n",
    "    save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch, arch_results in profile_results.items():\n",
    "    print(f\"===== {arch} =====\")\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
