{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf03514d",
   "metadata": {},
   "source": [
    "# Profile NeRF with Timeloop and Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2577da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent dir to path so we can import accelerating_nerfs\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899904e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIN COUNT 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/notebooks/../accelerating_nerfs/discretize_positional_enc.py:9: UserWarning: Failed to initialize NumPy: module compiled against API version 0xf but this version of numpy is 0xe (Triggered internally at /root/pytorch/torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import traceback\n",
    "\n",
    "from collections import defaultdict\n",
    "from accelerating_nerfs.models import VanillaNeRF, patch_forward\n",
    "\n",
    "# Custom code\n",
    "from analysis import *\n",
    "from profiler import Profiler\n",
    "from notebook_utils import natural_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870967",
   "metadata": {},
   "source": [
    "### Configure saving of profiling results\n",
    "This isn't important so you can ignore the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41223636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results in this dictionary\n",
    "profile_results = {}\n",
    "\n",
    "# Setup saving the profiling results\n",
    "results_dir = \"dot-product_profile_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    all_other_results = {}\n",
    "    \n",
    "    for arch, arch_results in profile_results.items():\n",
    "        # Write the super long results to it's own file\n",
    "        arch_results_path = os.path.join(results_dir, f\"{arch}_results.json\")\n",
    "        with open(arch_results_path, \"w\") as f:\n",
    "            json.dump(arch_results[\"results\"], f, indent=4)\n",
    "        \n",
    "        # Accumulate the other results as they're shorter and more readable\n",
    "        other_results = {\n",
    "            k: v for k, v in arch_results.items()\n",
    "            if k != \"results\"\n",
    "        }\n",
    "        # Have a pointer to the separate results file\n",
    "        other_results[\"results\"] = os.path.abspath(arch_results_path)\n",
    "        all_other_results[arch] = other_results\n",
    "    \n",
    "    results_path = os.path.join(results_dir, \"results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(all_other_results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved profile results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf13f07",
   "metadata": {},
   "source": [
    "## Profile using Timeloop and Accelergy\n",
    "I think we can safely ignore the 'No handlers found'\n",
    "\n",
    "To rerun things, delete the existing results in the `profiled_libs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4fa1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Running eyeriss_like\n",
      "====================\n",
      "Loaded profiled lib from ./dot-product_profiled_libs/eyeriss_like_profiled_lib.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./dot-product_profiled_libs/eyeriss_like_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 0.04\n",
      "total_cycle: 16.0\n",
      "Saved profile results to dot-product_profile_results/results.json\n",
      "=======================================\n",
      "Running eyeriss_like_onchip_compression\n",
      "=======================================\n",
      "Loaded profiled lib from ./dot-product_profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n",
      "Sparse optimization enabled for layer 1\n",
      "Sparse optimization enabled for layer 2\n",
      "Sparse optimization enabled for layer 3\n",
      "Sparse optimization enabled for layer 4\n",
      "Sparse optimization enabled for layer 5\n",
      "Sparse optimization enabled for layer 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 6/6 [00:25<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./dot-product_profiled_libs/eyeriss_like_onchip_compression_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 0.18\n",
      "total_cycle: 60.0\n",
      "Saved profile results to dot-product_profile_results/results.json\n",
      "=============================\n",
      "Running eyeriss_like_w_gating\n",
      "=============================\n",
      "Loaded profiled lib from ./dot-product_profiled_libs/eyeriss_like_w_gating_profiled_lib.json\n",
      "Sparse optimization enabled for layer 1\n",
      "Sparse optimization enabled for layer 2\n",
      "Sparse optimization enabled for layer 3\n",
      "Sparse optimization enabled for layer 4\n",
      "Sparse optimization enabled for layer 5\n",
      "Sparse optimization enabled for layer 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...: 100%|██████████| 6/6 [00:19<00:00,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profiled lib to ./dot-product_profiled_libs/eyeriss_like_w_gating_profiled_lib.json\n",
      "total_area: 0.0\n",
      "total_energy: 0.18\n",
      "total_cycle: 61.0\n",
      "Saved profile results to dot-product_profile_results/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Don't use simba_like or simple_output_stationary as the mapper constraints are too stringent\n",
    "archs_and_sparse = [\n",
    "#     (\"simple_weight_stationary\", False),\n",
    "#     (\"simple_output_stationary\", False),\n",
    "    (\"eyeriss_like\", False),\n",
    "    (\"eyeriss_like_onchip_compression\", True),\n",
    "    (\"eyeriss_like_w_gating\", True),\n",
    "    # (\"eyeriss_like_shen\", True),\n",
    "]\n",
    "failed_archs = set()\n",
    "\n",
    "for (arch, is_sparse) in archs_and_sparse:\n",
    "    msg = f\"Running {arch}\"\n",
    "    print(len(msg) * '=')\n",
    "    print(msg)\n",
    "    print(len(msg) * '=')\n",
    "    \n",
    "    # Profile - you shouldn't need to change anything here\n",
    "    try:\n",
    "        profiler = Profiler(\n",
    "            top_dir='workloads',\n",
    "            sub_dir=\"dot-product\" if not is_sparse else 'dot-product-sparse',\n",
    "            timeloop_dir=f\"designs/{arch}\",\n",
    "            arch_name=arch,\n",
    "            model=None,\n",
    "            input_size=None,\n",
    "            profiled_lib_dir_pattern=\"./dot-product_profiled_libs/{arch_name}_profiled_lib.json\",\n",
    "        )\n",
    "        results, summary, layer_summary = profiler.profile()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"ERROR: could not run profiler for {arch}, do not trust these results!\")\n",
    "        failed_archs.add(arch)\n",
    "        continue\n",
    "    \n",
    "    # Print summary information\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    profile_results[arch] = {\n",
    "        \"results\": results,\n",
    "        \"summary\": summary,\n",
    "        \"layer_summary\": layer_summary,\n",
    "    }\n",
    "    save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057b5ea",
   "metadata": {},
   "source": [
    "### <span style=\"color: red\">Analyze detailed results in \"Analyze Results.ipynb\"</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
