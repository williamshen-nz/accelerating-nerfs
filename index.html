<!--Thanks ChatGPT for the assistance in generating this -->
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Accelerating NeRFs</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Font -->
    <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">

    <!-- Include Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.2/font/bootstrap-icons.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="assets/style.css">
    <link rel="icon" type="image/png" href="assets/mit_logo.svg"/>

    <style>
    </style>
</head>
<body>
<div class="container-fluid main text-center">
    <div class="intro">
        <div class="row justify-content-center">
            <h2 class="title">üèéüí® Accelerating NeRFs: Optimizing Neural Radiance Fields with Specialized Hardware
                Architectures</h2>
        </div>
        <h5>
            <a href="https://shen.nz/" target="_blank">William Shen</a>*<sup>1</sup>,
            <a href="https://wmcclinton.github.io/" target="_blank">Willie McClinton</a>*<sup>1</sup>
        </h5>
        <p><sup>1</sup>MIT CSAIL</p>
        <p class="small-text">* Denotes equal contribution.</p>
        <div class="row justify-content-center" id="paper-buttons">
            <div class="asset-button">
                <a href="assets/paper.pdf" class="btn btn-primary" target="_blank">
                    <i class="bi bi-file-pdf"></i> Paper
                </a>
            </div>
            <div class="asset-button">
                <a href="https://github.com/williamshen-nz/accelerating-nerfs" class="btn btn-primary" target="_blank">
                    <i class="bi bi-code-slash"></i> Code
                </a>
            </div>
            <div class="asset-button">
                <a href="assets/poster.pdf" class="btn btn-primary" target="_blank">
                    <i class="bi bi-file-post"></i> Poster
                </a>
            </div>
        </div>
    </div>
    <hr>
    <div class="subsection text justify-content-center text-left" id="abstract">
        <h4 class="text-center">Abstract</h4>
        <p>
            Neural Radiance Fields (NeRFs) have recently seen an explosion in interest, with significant interest not
            only from computer vision and graphics researchers but also cinematographers, visual effects artists, and
            roboticists.
        </p>
        <p>
            Substantial efforts have been made to improve training and inference speeds, including algorithmic
            improvements such as multiresolution hash tables (Instant NGP) and voxel grids (DVGO), as well as
            architectural improvements such as using thousands of tiny MLPs (KiloNeRF) or extracting traditional 3D
            representations such as polygons from a NeRF (MobileNeRF).
        </p>
        <p>
            Despite this remarkable progress, limited attention has been paid to optimizing the dataflow and
            investigating the hardware acceleration potential of NeRFs, particularly during inference.
            The motivation of our project is to explore this untapped potential and decrease the computational
            requirements of NeRF models.
            We aim to answer the following key questions:
        </p>
        <ol>
            <li>Which components of the NeRF pipeline (e.g. positional encoding, ray sampling, MLP, volumetric
                rendering) are bottlenecks that are amenable to optimization and acceleration?
            </li>
            <li>Can we design hardware acceleration architectures to overcome these bottlenecks and better exploit
                NeRF dataflows?
            </li>
            <li>How does this affect the performance of NeRF for metrics such as rendering quality, computational
                resources, and energy usage?
            </li>
        </ol>
    </div>
    <hr>
    <div class="subsection">
        <h4>Table of Contents</h4>
        <div class="text">
            <a href="#background">NeRF Background</a><br>
            <a href="#sparsity">Exploiting Activation Sparsity</a><br>
            <a href="#volumetric-rendering">Accelerating Volumetric Rendering</a><br>
            <a href="#quantization">Quantization</a>
        </div>
    </div>
    <hr>
    <div class="nerf-videos" id="background">
        <h4>NeRF Background</h4>
        <div id="nerf-architecture" style="max-width: 750px; margin: 1.5rem auto;">
            <img src="assets/nerf-architecture.png" style="margin-bottom: 1rem" class="img-fluid"
                 alt="NeRF Architecture">
            <p class="text text-left small-text">
                <strong>Figure 1:</strong> the NeRF architecture we consider (figure modified from
                <a href="https://arxiv.org/abs/2003.08934" target="_blank">Mildenhall et al. 2020</a>). There are 12
                fully-connected layers (blue and red blocks) in the MLP. The blocks with black
                arrows use the ReLU activation function.
            </p>
        </div>
        <hr>
        <p>Videos rendered from our NeRF implementation using 32-bit floating point precision.</p>
        <div class="d-block d-sm-none">
            <p class="small-text" style="color: rgb(35,187,35)">Turn your phone sideways to view.</p>
        </div>
        <div class="d-none d-sm-block">
            <div class="row justify-content-center">
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/chair.mp4" autoplay loop muted></video>
                    <div class="video-title">Chair</div>
                </div>
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/drums.mp4" autoplay loop muted></video>
                    <div class="video-title">Drums</div>
                </div>
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/ficus.mp4" autoplay loop muted></video>
                    <div class="video-title">Ficus</div>
                </div>
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/hotdog.mp4" autoplay loop muted></video>
                    <div class="video-title">Hotdog</div>
                </div>
            </div>
            <div class="row justify-content-center">
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/lego.mp4" autoplay loop muted></video>
                    <div class="video-title">Lego</div>
                </div>
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/materials.mp4" autoplay loop muted></video>
                    <div class="video-title">Materials</div>
                </div>
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/mic.mp4" autoplay loop muted></video>
                    <div class="video-title">Mic</div>
                </div>
                <div class="col-sm-2 col-md-2 video-container">
                    <video src="assets/ship.mp4" autoplay loop muted></video>
                    <div class="video-title">Ship</div>
                </div>
            </div>
        </div>
    </div>
    <hr>
    <div class="subsection text-left" id="sparsity">
        <h4 class="text-center">Exploiting Activation Sparsity</h4>
        <div class="text justify-content-center">
            <p>
                Our NeRF model consists of 12 fully-connected (FC) layers, 10 of which use the ReLU activation function
                hence resulting in sparse activations. This results in a significant number of ineffectual computations,
                which spend unnecessary energy and computation time.
            </p>
            <p>
                We propose to exploit this activation sparsity by using compressed representations, along with gating
                and skipping to avoid carrying out unnecesary computations. We profile the sparsity of the activations
                of the FC layers of NeRFs trained on the synthetic dataset benchmark, and show the input activation
                sparsities in the figures below.
            </p>
            <p>
                We find that the overall input activation sparsity is 60.3% across the FC layers, excluding fc_1 and
                fc_11. Note that fc_1 receives the position-encoded ray samples while fc_11 receives the output from
                fc_10 which does not have an activation function.
            </p>
        </div>
        <div id="activationSparsityCrop">
            <img src="assets/activation-sparsity-crop.png" alt="Activation Sparsity (Cropped)" class="img-fluid">
        </div>
        <div class="d-none" id="activationSparsity">
            <img src="assets/activation-sparsity.png" alt="Activation Sparsity" class="img-fluid">
        </div>
        <div class="row text-center justify-content-center" style="margin: 1.5rem auto;">
            <div class="col-sm-12">
                <button class="btn btn-secondary" id="activationSparsityBtn">Show More üìä</button>
            </div>
        </div>
        <div class="text justify-content-center">
            <p>
                We use the Eyeriss architecture to accelerate the NeRF model, and gain a significant reduction in energy
                and cycles by exploiting the activation sparsity. See the table below for the results and the
                <a href="assets/paper.pdf">paper</a> for more details.
            </p>
            <!-- TODO: image of table -->
            <div style="max-width: 600px; margin: 1.5rem auto;">
                <img src="assets/eyeriss-results.png" alt="Eyeriss Results" class="img-fluid">
            </div>
        </div>
    </div>
    <hr>
    <div class="subsection" id="volumetric-rendering">
        <h4 class="text-center">Accelerating Volumetric Rendering</h4>
        <p>TODO: Willie</p>
    </div>
    <hr>
    <div class="subsection" id="quantization">
        <h4 class="text-center">Quantization</h4>
        <div class="text text-left justify-content-center">
            <p>
                The NeRF models by default use 32-bit floating point numbers (FP32). We quantize the
                models to FP16 and achieve significant speedups and reductions in energy (>2-3x üèéüí® improvement in
                rendering time) at the cost of marginally decreased peak signal-to-noise ratio (PSNR).
            </p>
            <p>
                While the PSNR is decreased, it is difficult to observe any visible difference between the images
                rendered from the FP32 and FP16 models. Thus, FP16 could be sufficient for many applications and
                additionally comes at the benefit of 2x smaller model size (from 2.4MB to 1.2MB).
            </p>
            <p class="small-text" style="color: #a1a1a1">
                Note: we run FP32 and FP16 using PyTorch on a NVIDIA RTX 3090 GPU to determine the render time.
                We estimate energy by multiplying the render time by the average power consumption of the
                GPU.
                <!-- FP32 peak 343W, FP16 peak 326W -->
            </p>
        </div>
        <div class="nerf-videos">
            <div class="row justify-content-center">
                <div class="col-sm-3 col-md-3 col-lg-3 video-container">
                    <h5>Lego (FP32)</h5>
                    <video src="assets/lego.mp4" autoplay loop muted></video>
                    <p>
                        PSNR (avg) = 33.72 dB<br>
                        <span style="color:red">üêå Render Time = 154.57s</span><br>
                        <span style="color:red">üè≠ Energy = 49.98 kJ</span>
                    </p>
                </div>
                <div class="col-sm-3 col-md-3 col-lg-3 video-container">
                    <h5>Lego (FP16)</h5>
                    <video src="assets/lego_fp16.mp4" autoplay loop muted></video>
                    <p>
                        PSNR (avg) = 32.74 dB<br>
                        <span style="color:green">üèéüí® Render Time = 54.09s</span><br>
                        <span style="color:green">üîã Energy = 15.89 kJ</span>
                    </p>
                </div>
            </div>
            <div class="d-none" id="hiddenVideos">
                <div class="row justify-content-center">
                    <div class="col-sm-3 col-md-3 col-lg-3 video-container">
                        <h5>Ficus (FP32)</h5>
                        <video src="assets/ficus.mp4" autoplay loop muted></video>
                        <p>
                            PSNR (avg) = 32.93 dB<br>
                            <span style="color:red">üêå Render Time = 60.63s</span><br>
                            <span style="color:red">üè≠ Energy = 18.38 kJ</span>
                        </p>
                    </div>
                    <div class="col-sm-3 col-md-3 col-lg-3 video-container">
                        <h5>Ficus (FP16)</h5>
                        <video src="assets/ficus_fp16.mp4" autoplay loop muted></video>
                        <p>
                            PSNR (avg) = 32.07 dB<br>
                            <span style="color:green">üèéüí® Render Time = 26.21s</span><br>
                            <span style="color:green">üîã Energy = 6.58 kJ</span>
                        </p>
                    </div>
                </div>
                <div class="row justify-content-center">
                    <div class="col-sm-3 col-md-3 col-lg-3 video-container">
                        <h5>Ship (FP32)</h5>
                        <video src="assets/ship.mp4" autoplay loop muted></video>
                        <p>
                            PSNR (avg) = 29.85 dB<br>
                            <span style="color:red"> üêå Render Time = 354.27s</span><br>
                            <span style="color:red">üè≠ Energy = 119.35 kJ</span>
                        </p>
                    </div>
                    <div class="col-sm-3 col-md-3 col-lg-3 video-container">
                        <h5>Ship (FP16)</h5>
                        <video src="assets/ship_fp16.mp4" autoplay loop muted></video>
                        <p>
                            PSNR (avg) = 29.43 dB<br>
                            <span style="color:green">üèéüí® Render Time = 114.59s</span><br>
                            <span style="color:green">üîã Energy = 36.19 kJ</span>
                        </p>
                    </div>
                </div>
            </div>
            <div class="row justify-content-center">
                <div class="col-sm-12">
                    <button class="btn btn-secondary" id="quantVideosBtn">Show More üé•</button>
                </div>
                <p class="small-text" style="padding-top: 1rem;">
                    Videos not showing?
                    <a href="#quantization" onclick="location.reload()">Try refresh</a>
                </p>
            </div>
        </div>
    </div>
    <hr>
    <div class="footer">
        <p class="small-text">
            Course project for
            <a href="http://csg.csail.mit.edu/6.5930/index.html" target="_blank">
                6.5930 Hardware Architecture for Deep Learning - Spring 2023
            </a>
        </p>
    </div>
</div>

<script>
    // Show activation sparsity
    const activationSparsityBtn = document.getElementById("activationSparsityBtn");
    const activationSparsity = document.getElementById("activationSparsity");
    const activationSparsityCrop = document.getElementById("activationSparsityCrop");

    activationSparsityBtn.addEventListener("click", () => {
        activationSparsity.classList.toggle("d-none");
        activationSparsityCrop.classList.toggle("d-none");
        if (activationSparsityBtn.textContent === "Show More üìä") {
            activationSparsityBtn.textContent = "Hide üìä";
        } else {
            activationSparsityBtn.textContent = "Show More üìä";
        }
    });

    // Toggle hidden videos
    const quantVideosBtn = document.getElementById("quantVideosBtn");
    const hiddenVideos = document.getElementById("hiddenVideos");

    quantVideosBtn.addEventListener("click", () => {
        hiddenVideos.classList.toggle("d-none");
        if (quantVideosBtn.textContent === "Show More üé•") {
            quantVideosBtn.textContent = "Hide üé•";
        } else {
            quantVideosBtn.textContent = "Show More üé•";
        }
    });
</script>
</body>
</html>